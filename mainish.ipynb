{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msetuptools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expand_dims\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_img\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import setuptools.dist\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "class ArtBench10(CIFAR10):\n",
    "\n",
    "    base_folder = \"artbench-10-batches-py\"\n",
    "    url = \"https://artbench.eecs.berkeley.edu/files/artbench-10-python.tar.gz\"\n",
    "    filename = \"artbench-10-python.tar.gz\"\n",
    "    tgz_md5 = \"9df1e998ee026aae36ec60ca7b44960e\"\n",
    "    train_list = [\n",
    "        [\"data_batch_1\", \"c2e02a78dcea81fe6fead5f1540e542f\"],\n",
    "        [\"data_batch_2\", \"1102a4dcf41d4dd63e20c10691193448\"],\n",
    "        [\"data_batch_3\", \"177fc43579af15ecc80eb506953ec26f\"],\n",
    "        [\"data_batch_4\", \"566b2a02ccfbafa026fbb2bcec856ff6\"],\n",
    "        [\"data_batch_5\", \"faa6a572469542010a1c8a2a9a7bf436\"],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        [\"test_batch\", \"fa44530c8b8158467e00899609c19e52\"],\n",
    "    ]\n",
    "    meta = {\n",
    "        \"filename\": \"meta\",\n",
    "        \"key\": \"styles\",\n",
    "        \"md5\": \"5bdcafa7398aa6b75d569baaec5cd4aa\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ArtBench10(root = \"./train_data\", train = True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ArtBench10(root = \"./test_data\", train = False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_1\")\n",
    "X_train1 = output['data']\n",
    "y_train1 = output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3072), 10000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "X_train1.shape, len(y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# load each of the 5 batches (for loop)\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_1\")\n",
    "X_train1 = output['data']\n",
    "y_train1 = output['labels']\n",
    "\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_2\")\n",
    "X_train2 = output['data']\n",
    "y_train2 = output['labels']\n",
    "\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_3\")\n",
    "X_train3 = output['data']\n",
    "y_train3 = output['labels']\n",
    "\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_4\")\n",
    "X_train4 = output['data']\n",
    "y_train4 = output['labels']\n",
    "\n",
    "output = unpickle(\"./train_data/artbench-10-batches-py/data_batch_5\")\n",
    "X_train5 = output['data']\n",
    "y_train5 = output['labels']\n",
    "\n",
    "\n",
    "output = unpickle(\"./test_data/artbench-10-batches-py/test_batch\")\n",
    "X_test = output['data']\n",
    "y_test = output['labels']\n",
    "\n",
    "# use np.vstack to stack all the arrays from the batches (10000, 3072) x 5 -> (50000, 3072) to make X_train\n",
    "X_train = np.vstack((X_train1,X_train2,X_train3,X_train4,X_train5))\n",
    "y_train = np.concatenate((y_train1,y_train2,y_train3,y_train4,y_train5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000,) (10000, 3072) 10000\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# check the shapes of the arrays after vstack\n",
    "print(X_train.shape, y_train.shape, X_test.shape, len(y_test))\n",
    "#(50000, 3072), 50000, (10000, 3072), 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional, consider going to Open Lab] TODO:\n",
    "# write out the arrays to a file\n",
    "# make a new ipynb which loads in those arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_flattened dimension:  (50000, 3072)\n",
      "X_test_flattened dimension:  (10000, 3072)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train_flattened dimension: \u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_flattened\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test_flattened dimension: \u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test_flattened\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      8\u001b[0m knn_model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     10\u001b[0m knn_model\u001b[38;5;241m.\u001b[39mfit(X_train_flattened, y_train)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
    "print(\"X_train_flattened dimension: \", X_train_flattened.shape)\n",
    "print(\"X_test_flattened dimension: \", X_test_flattened.shape)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "knn_model.fit(X_train_flattened, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
